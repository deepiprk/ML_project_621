{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T03:14:38.864036Z",
     "start_time": "2018-12-03T03:14:38.306430Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import datetime\n",
    "import math\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T00:00:48.712295Z",
     "start_time": "2018-12-03T00:00:26.338307Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Loading data...')\n",
    "data_path = '/Users/alvira/Desktop/ml1/kaggle/music/'\n",
    "train = pd.read_csv('train.csv', dtype={'msno' : 'object',\n",
    "                                                'source_system_tab' : 'object',\n",
    "                                                  'source_screen_name' : 'object',\n",
    "                                                  'source_type' : 'object',\n",
    "                                                  'target' : np.uint8,\n",
    "                                                  'song_id' : 'object'})\n",
    "test = pd.read_csv('test.csv', dtype={'msno' : 'object',\n",
    "                                                'source_system_tab' : 'object',\n",
    "                                                'source_screen_name' : 'object',\n",
    "                                                'source_type' : 'object',\n",
    "                                                'song_id' : 'object'})\n",
    "songs = pd.read_csv('songs.csv',dtype={'genre_ids': 'object',\n",
    "                                                  'language' : 'object',\n",
    "                                                  'artist_name' : 'object',\n",
    "                                                  'composer' : 'object',\n",
    "                                                  'lyricist' : 'object',\n",
    "                                                  'song_id' : 'object'})\n",
    "members = pd.read_csv('members.csv',dtype={'city' : 'object',\n",
    "                                                      'bd' : np.uint8,\n",
    "                                                      'gender' : 'object',\n",
    "                                                      'registered_via' : 'object'},\n",
    "                     parse_dates=['registration_init_time','expiration_date'])\n",
    "songs_extra = pd.read_csv('song_extra_info.csv')\n",
    "print('Done loading...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T00:01:11.720709Z",
     "start_time": "2018-12-03T00:00:51.731228Z"
    }
   },
   "outputs": [],
   "source": [
    "def object2cat(df):\n",
    "    object_cols = list(df.select_dtypes(include=['object']).columns)\n",
    "    for col in object_cols:\n",
    "        df[col]=df[col].astype('category')\n",
    "object2cat(train)\n",
    "object2cat(test)\n",
    "object2cat(songs)\n",
    "object2cat(members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T00:02:27.594907Z",
     "start_time": "2018-12-03T00:01:56.485916Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Data merging...')\n",
    "\n",
    "\n",
    "train = train.merge(songs, on='song_id', how='left')\n",
    "test = test.merge(songs, on='song_id', how='left')\n",
    "\n",
    "members['membership_days'] = members['expiration_date'].subtract(members['registration_init_time']).dt.days.astype(int)\n",
    "\n",
    "members['registration_year'] = members['registration_init_time'].dt.year\n",
    "members['registration_month'] = members['registration_init_time'].dt.month\n",
    "members['registration_date'] = members['registration_init_time'].dt.day\n",
    "\n",
    "members['expiration_year'] = members['expiration_date'].dt.year\n",
    "members['expiration_month'] = members['expiration_date'].dt.month\n",
    "members['expiration_date'] = members['expiration_date'].dt.day\n",
    "members = members.drop(['registration_init_time'], axis=1)\n",
    "\n",
    "def isrc_to_year(isrc):\n",
    "    if type(isrc) == str:\n",
    "        if int(isrc[5:7]) > 17:\n",
    "            return 1900 + int(isrc[5:7])\n",
    "        else:\n",
    "            return 2000 + int(isrc[5:7])\n",
    "    else:\n",
    "        return np.nan\n",
    "        \n",
    "songs_extra['song_year'] = songs_extra['isrc'].apply(isrc_to_year)\n",
    "songs_extra.drop(['isrc', 'name'], axis = 1, inplace = True)\n",
    "\n",
    "train = train.merge(members, on='msno', how='left')\n",
    "test = test.merge(members, on='msno', how='left')\n",
    "\n",
    "train = train.merge(songs_extra, on = 'song_id', how = 'left')\n",
    "train.song_length.fillna(200000,inplace=True)\n",
    "train.song_length = train.song_length.astype(np.uint32)\n",
    "train.song_id = train.song_id.astype('category')\n",
    "\n",
    "\n",
    "test = test.merge(songs_extra, on = 'song_id', how = 'left')\n",
    "test.song_length.fillna(200000,inplace=True)\n",
    "test.song_length = test.song_length.astype(np.uint32)\n",
    "test.song_id = test.song_id.astype('category')\n",
    "import gc\n",
    "del members, songs; gc.collect();\n",
    "\n",
    "print('Done merging...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T00:04:01.500844Z",
     "start_time": "2018-12-03T00:04:01.494011Z"
    }
   },
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T00:04:20.139902Z",
     "start_time": "2018-12-03T00:04:16.425110Z"
    }
   },
   "outputs": [],
   "source": [
    "print (\"Adding new features\")\n",
    "\n",
    "def genre_id_count(x):\n",
    "    if x == 'no_genre_id':\n",
    "        return 0\n",
    "    else:\n",
    "        return x.count('|') + 1\n",
    "\n",
    "\n",
    "train['genre_ids'].cat.add_categories('no_genre_id').fillna('no_genre_id',inplace=True)\n",
    "test['genre_ids'].cat.add_categories('no_genre_id').fillna('no_genre_id',inplace=True)\n",
    "train['genre_ids_count'] = train['genre_ids'].apply(genre_id_count).astype(np.int8)\n",
    "test['genre_ids_count'] = test['genre_ids'].apply(genre_id_count).astype(np.int8)\n",
    "\n",
    "def lyricist_count(x):\n",
    "    if x == 'no_lyricist':\n",
    "        return 0\n",
    "    else:\n",
    "        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n",
    "    return sum(map(x.count, ['|', '/', '\\\\', ';']))\n",
    "\n",
    "train['lyricist'].cat.add_categories('no_lyricist').fillna('no_lyricist',inplace=True)\n",
    "test['lyricist'].cat.add_categories('no_lyricist').fillna('no_lyricist',inplace=True)\n",
    "train['lyricists_count'] = train['lyricist'].apply(lyricist_count).astype(np.int8)\n",
    "test['lyricists_count'] = test['lyricist'].apply(lyricist_count).astype(np.int8)\n",
    "\n",
    "def composer_count(x):\n",
    "    if x == 'no_composer':\n",
    "        return 0\n",
    "    else:\n",
    "        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n",
    "\n",
    "train['composer'].cat.add_categories('no_composer').fillna('no_composer',inplace=True)\n",
    "test['composer'].cat.add_categories('no_composer').fillna('no_composer',inplace=True)\n",
    "train['composer_count'] = train['composer'].apply(composer_count).astype(np.int8)\n",
    "test['composer_count'] = test['composer'].apply(composer_count).astype(np.int8)\n",
    "\n",
    "def is_featured(x):\n",
    "    if 'feat' in str(x) :\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "train['artist_name'].cat.add_categories('no_artist').fillna('no_artist',inplace=True)\n",
    "test['artist_name'].cat.add_categories('no_artist').fillna('no_artist',inplace=True)\n",
    "train['is_featured'] = train['artist_name'].apply(is_featured).astype(np.int8)\n",
    "test['is_featured'] = test['artist_name'].apply(is_featured).astype(np.int8)\n",
    "\n",
    "def artist_count(x):\n",
    "    if x == 'no_artist':\n",
    "        return 0\n",
    "    else:\n",
    "        return x.count('and') + x.count(',') + x.count('feat') + x.count('&')\n",
    "\n",
    "train['artist_count'] = train['artist_name'].apply(artist_count).astype(np.int8)\n",
    "test['artist_count'] = test['artist_name'].apply(artist_count).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T00:04:32.084190Z",
     "start_time": "2018-12-03T00:04:30.647373Z"
    }
   },
   "outputs": [],
   "source": [
    "train['artist_name'].astype(\"object\") == train['composer'].astype(\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T00:04:58.104803Z",
     "start_time": "2018-12-03T00:04:45.334238Z"
    }
   },
   "outputs": [],
   "source": [
    "# if artist is same as composer\n",
    "train['artist_composer'] = (train['artist_name'].astype(\"object\") == train['composer'].astype(\"object\")).astype(np.int8)\n",
    "test['artist_composer'] = (test['artist_name'].astype(\"object\") == test['composer'].astype(\"object\")).astype(np.int8)\n",
    "\n",
    "\n",
    "# if artist, lyricist and composer are all three same\n",
    "train['artist_composer_lyricist'] = ((train['artist_name'].astype(\"object\") == train['composer'].astype(\"object\")) & (train['artist_name'].astype(\"object\") == train['lyricist'].astype(\"object\")) & (train['composer'].astype(\"object\") == train['lyricist'].astype(\"object\"))).astype(np.int8)\n",
    "test['artist_composer_lyricist'] = ((test['artist_name'].astype(\"object\") == test['composer'].astype(\"object\")) & (test['artist_name'].astype(\"object\") == test['lyricist'].astype(\"object\")) & (test['composer'].astype(\"object\") == test['lyricist'].astype(\"object\"))).astype(np.int8)\n",
    "\n",
    "# is song language 17 or 45. \n",
    "def song_lang_boolean(x):\n",
    "    if '17.0' in str(x) or '45.0' in str(x):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "train['song_lang_boolean'] = train['language'].apply(song_lang_boolean).astype(np.int8)\n",
    "test['song_lang_boolean'] = test['language'].apply(song_lang_boolean).astype(np.int8)\n",
    "\n",
    "\n",
    "_mean_song_length = np.mean(train['song_length'])\n",
    "def smaller_song(x):\n",
    "    if x < _mean_song_length:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "train['smaller_song'] = train['song_length'].apply(smaller_song).astype(np.int8)\n",
    "test['smaller_song'] = test['song_length'].apply(smaller_song).astype(np.int8)\n",
    "\n",
    "# number of times a song has been played before\n",
    "_dict_count_song_played_train = {k: v for k, v in train['song_id'].value_counts().iteritems()}\n",
    "_dict_count_song_played_test = {k: v for k, v in test['song_id'].value_counts().iteritems()}\n",
    "def count_song_played(x):\n",
    "    try:\n",
    "        return _dict_count_song_played_train[x]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            return _dict_count_song_played_test[x]\n",
    "        except KeyError:\n",
    "            return 0\n",
    "    \n",
    "\n",
    "train['count_song_played'] = train['song_id'].apply(count_song_played).astype(np.int64)\n",
    "test['count_song_played'] = test['song_id'].apply(count_song_played).astype(np.int64)\n",
    "\n",
    "# number of times the artist has been played\n",
    "_dict_count_artist_played_train = {k: v for k, v in train['artist_name'].value_counts().iteritems()}\n",
    "_dict_count_artist_played_test = {k: v for k, v in test['artist_name'].value_counts().iteritems()}\n",
    "def count_artist_played(x):\n",
    "    try:\n",
    "        return _dict_count_artist_played_train[x]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            return _dict_count_artist_played_test[x]\n",
    "        except KeyError:\n",
    "            return 0\n",
    "\n",
    "train['count_artist_played'] = train['artist_name'].apply(count_artist_played).astype(np.int64)\n",
    "test['count_artist_played'] = test['artist_name'].apply(count_artist_played).astype(np.int64)\n",
    "\n",
    "\n",
    "print(\"Done adding features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T00:05:20.482724Z",
     "start_time": "2018-12-03T00:05:18.357667Z"
    }
   },
   "outputs": [],
   "source": [
    "print (\"Train test and validation sets\")\n",
    "for col in train.columns:\n",
    "    if train[col].dtype == object:\n",
    "        train[col] = train[col].astype('category')\n",
    "        test[col] = test[col].astype('category')\n",
    "\n",
    "\n",
    "X_train = train.drop(['target'], axis=1)\n",
    "y_train = train['target'].values\n",
    "\n",
    "\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "ids = test['id'].values\n",
    "\n",
    "\n",
    "# del train, test; gc.collect();\n",
    "\n",
    "d_train_final = lgb.Dataset(X_train, y_train)\n",
    "watchlist_final = lgb.Dataset(X_train, y_train)\n",
    "print('Processed data...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T00:57:16.120251Z",
     "start_time": "2018-12-03T00:57:16.037658Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train.to_csv(\"processed_train_1.csv\")\n",
    "test.to_csv(\"test_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T00:11:27.189295Z",
     "start_time": "2018-12-03T00:11:27.163224Z"
    }
   },
   "outputs": [],
   "source": [
    "del songs_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T03:14:44.272760Z",
     "start_time": "2018-12-03T03:14:44.223738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T03:15:23.769437Z",
     "start_time": "2018-12-03T03:14:45.972972Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"processed_train_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T03:15:43.091664Z",
     "start_time": "2018-12-03T03:15:23.770951Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    if train[col].dtype == object:\n",
    "        train[col] = train[col].astype('category')\n",
    "  #      test[col] = test[col].astype('category')\n",
    "        \n",
    "\n",
    "y_train = train['target'].values\n",
    "X_train = train.drop(['target'], axis=1)\n",
    "\n",
    "#X_test = test.drop(['id'], axis=1)\n",
    "#ids = test['id'].values\n",
    "d_train_final = lgb.Dataset(X_train, y_train)\n",
    "watchlist_final = lgb.Dataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T00:24:22.173414Z",
     "start_time": "2018-12-03T00:16:19.212316Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting': 'gbdt',\n",
    "        'learning_rate': 0.3 ,\n",
    "        'verbose': 0,\n",
    "        'num_leaves': 108,\n",
    "        'bagging_fraction': 0.95,\n",
    "        'bagging_freq': 1,\n",
    "        'bagging_seed': 1,\n",
    "        'feature_fraction': 0.9,\n",
    "        'feature_fraction_seed': 1,\n",
    "        'max_bin': 256,\n",
    "        'max_depth': 10,\n",
    "        'num_rounds': 200,\n",
    "        'metric' : 'auc'\n",
    "    }\n",
    "\n",
    "%time model_f1 = lgb.train(params, train_set=d_train_final,  valid_sets=watchlist_final, verbose_eval=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T03:15:53.766543Z",
     "start_time": "2018-12-03T03:15:43.093332Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_all, X_test, y_train_all, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_all, y_train_all, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-03T02:45:13.058Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "sk_reg = lgb.sklearn.LGBMClassifier(\n",
    "         objective='binary',\n",
    "         eval_metric='binary_logloss',\n",
    "         boosting='gbdt',\n",
    "         learning_rate=0.3 ,\n",
    "         verbose=0,\n",
    "         num_leaves=108,\n",
    "         bagging_freq= 1,\n",
    "         bagging_seed= 1,\n",
    "         feature_fraction= 0.9,\n",
    "         feature_fraction_seed= 1,\n",
    "         max_bin= 256,\n",
    "         max_depth= 50,\n",
    "         num_rounds= 200,\n",
    ")\n",
    "sk_reg.fit(X_train, Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T01:13:20.786231Z",
     "start_time": "2018-12-03T01:09:23.264321Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predicted = sk_reg.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test, predicted)\n",
    "print(f'Mean accuracy score: {accuracy:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T03:27:26.396645Z",
     "start_time": "2018-12-03T03:15:53.770472Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditi/anaconda3/envs/ml/lib/python3.7/site-packages/lightgbm/engine.py:116: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_freq=1, bagging_seed=1, boosting='gbdt',\n",
       "        boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        eval_metric='binary_logloss', feature_fraction=0.9,\n",
       "        feature_fraction_seed=1, importance_type='split',\n",
       "        learning_rate=0.3, max_bin=256, max_depth=300,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_leaves=600, num_rounds=200,\n",
       "        objective='binary', random_state=None, reg_alpha=0.0,\n",
       "        reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=0, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sk_reg = lgb.sklearn.LGBMClassifier(\n",
    "         objective='binary',\n",
    "         eval_metric='binary_logloss',\n",
    "         boosting='gbdt',\n",
    "         learning_rate=0.3 ,\n",
    "         verbose=0,\n",
    "         num_leaves=600,\n",
    "         bagging_freq= 1,\n",
    "         bagging_seed= 1,\n",
    "         feature_fraction= 0.9,\n",
    "         feature_fraction_seed= 1,\n",
    "         max_bin= 256,\n",
    "         max_depth= 300,\n",
    "         num_rounds= 200,\n",
    ")\n",
    "sk_reg.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T03:33:52.054453Z",
     "start_time": "2018-12-03T03:28:13.162962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy score: 0.763\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predicted = sk_reg.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, predicted)\n",
    "print(f'Mean accuracy score: {accuracy:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T02:07:17.893275Z",
     "start_time": "2018-12-03T02:01:44.796701Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predicted = sk_reg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print(f'Mean accuracy score: {accuracy:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
